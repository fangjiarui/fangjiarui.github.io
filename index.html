---
layout: default
title: Jiarui Fang
---
<div><!-- Do I want to show a pic on the phone screen?-->
<div class="rightphoto"><img src="assets/img/fangjiaruiv3.jpeg" alt="photo" width="200px" /></div>
<div class="leftpad">
<h3>Jiarui Fang (方佳瑞)</h3>
<h5><a href="mailto:fangjiarui123@gmail.com">fangjiarui123 AT gmail.com</a></h5>
<p>
  I am currently a principal software engineer at Tencent, the leader of a team for developing distributed software for Large Lauguague/Diffusion Models (LLMs/DiTs) on heterogeneous hardware platforms, including NVIDIA GPU, Intel Gaudi and domestic NPUs.
  I initialized the open-sourced project <a href="https://github.com/xdit-project/xDiT">xDiT</a>, A Scalable Inference Engine for Diffusion Transformers (DiTs) on multi-GPUs.
</p>
<p>
  Over the span of a year and a half, I have had two startup experiences. 
  I was one of the technical partners at LightYearAI, serving as the first technical member upon the company's inception. 
  I led a team of 20+ members, with the responsibility of data curation for the pre-training of large language models.
  The company was acquired by Meituan Inc just three months after its establishment.
  Prior to that, I was the CTO of a startup company dedicated to open-source AI infrastructures, where I led the project <a href="https://github.com/hpcaitech/ColossalAI">ColossalAI</a>, a training framework for large language models.
</p>
<p>
  Before that, I was a senior engineer at Wechat AI, Tencent. 
  My work was focused on improving the efficiency of online and offline AI applications with innovative parallel computing techniques.
  I also took part in the development of some basic modules in the WeChat App, including the <a href="https://z.weixin.qq.com/">WeChat Input Method Engine</a> and the WeChat Translation System.
  At Wechat AI, I initialized two popular open-sourced software, e.g. TurboTransformers</a>, a fast runtime for transformer inference on CPU and GPU, 
  <a href="https://github.com/Tencent/PatrickStar">PatrickStar</a>, a parallel training framework for large language models.
  In 2021, I was honored with the company's highest-valued individual award for my outstanding contributions to open-source collaboration.
  I later learned that PatrickStar played a significant role in training the <a href="https://hunyuan.tencent.com/">Tencent Hunyuan LLM</a> in 2023. 
</p>
<p>
  I received a Ph.D. in Computer Science from Tsinghua University in 2019.
  My advisors are Prof. <a href="https://www.cs.tsinghua.edu.cn/info/1107/3507.htm">Guangwen Yang</a> and Prof. <a href="http://47.94.243.94/mediawiki/index.php/Haohuan_Fu">Haohuan Fu</a>. 
  My research focused on applying High-Performance Computing (HPC) for scientific applications. 
  The title of <a href="https://fangjiarui.github.io/assets/pdf/fangjiarui_phd_thesis.pdf">my doctoral dissertation</a> is <i>Parallel Deep Learning Training System on Sunway TaihuLight</i>.
  I served as a visiting scholar under the supervision of <a href="https://web.cs.ucla.edu/~chohsieh/">Cho-Jui Hsieh</a> at the University of California, Davis, from 2018 to 2019.
</p>
<p>
  I enjoy sports. 
  My hobbies include jogging, football, swimming, and table tennis.
  You can follow me on <a href="https://www.zhihu.com/people/feifeibear">知乎</a> and <a href="https://github.com/feifeibear">Github</a>.
</p>
</div>
</div>
<p>&nbsp;</p>
<!--<a href="projects.html"> [Unpublished Projects]</a>-->
<p>&nbsp;&nbsp;</p>
<!--
 *** Software ***

<h3>
  <a name='software'></a> Software 
</h3>

{% include software.html %}
--><!--
 *** Teaching ***

<h3>
  <a name='teaching'></a> Teaching (GSI)
</h3>

{% include teaching.html %}
-->

<body>
<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=IUauw8ewM48TcdV7vaC71gwnoW5ILE5GvL1ZyMOfBh0&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff"></script>
</body>
