<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/swcaffelogo.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>SWCaffe: A Deep Learning Framework for the Sunway TaihuLight</strong><br/>Jiarui Fang<br />
      <a href="assets/pdf/swcaffe.pdf">[Technical Report PDF]</a>
    </p>
    <p class="abstract-text">
    Based on our previous work swDNN, we propose the SWCaffe \cite{url:swcaffe} which maps one of the most popular deep learning framework Caffe to the Sunway TaihuLight.
    SWCaffe is a fully optimized framework where major memory and computing operations are conducted on CPEs of SW26010.
    We categorize operations in a DNN as computing-centric and memory-centric kernels and provide parallel design for them considering the architectural characteristics.
    We compare the performance in one CG (742.4 GFlops) with intel 12-core E52680 V3 CPU (1280 GFlops).
Our framework beats intel-Caffe with a speedup of 1.50x on VGG-16 network with single-precision floating-point data.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/swdnnlogo.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>swDNN: A Library for Accelerating Deep Learning Applications on Sunway TaihuLight Supercomputer</strong><br />
     Jiarui Fang, Haohuan Fu, et al., 31st IEEE International Parallel & Distributed Processing Symposium (IPDPS 2017), 2017.6<br />
      <a href="assets/pdf/swdnn-ipdps-2017.pdf">[Conference PDF]</a>
      <a href="assets/pdf/swDNN-IPDPS-final-ppt.pdf">[PPT]</a>
      <a href="assets/pdf/optimiza-CNN.pdf">[Journal PDF]</a>
      <a href="https://github.com/THUHPGC/swDNN">[Software]</a>
    </p>
    <p class="abstract-text">
    We report our work on swDNN, which is a highly- efficient library for accelerating deep learning applications. We derive a performance model that guides us in the process of identifying the most suitable approach for mapping the convolutional neural networks (CNNs) onto bottom hardware. By performing a systematic optimization that explores major factors, such as organization of convolution loops, blocking techniques, register data communication schemes, as well as reordering strategies for the two pipelines of instructions, we manage to achieve a double-precision performance over 1.6 Tflops for the convolution kernel, achieving 54% of the theoretical peak. Compared with Tesla K40m with cuDNNv5, swDNN results in 1.91-9.75x performance speedup in an evaluation with over 100 parameter configurations.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/hipclogo.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Cache-friendly Design for Complex Spatially-variable Coe cient Stencils on Many-core Architectures</strong><br />
      Jiarui Fang, Haohuan Fu and Guangwen Yang. IEEE 23rd International Conference on High Performance Computing, Data, and Analytics (HiPC 2016), 2016.12
      <a href="assets/pdf/HiPC2016-finial-submit.pdf">[PDF]</a>
    </p>
    <p class="abstract-text">
    Many-core architectures, such as the NVIDIA graphics processing unit and Intel Xeon Phi, which are char- acterized by high computation resources but limited on-chip memory capacity, have been used to significantly accelerate various computationally demanding tasks. Stencil operators are naturally suitable for such architectures because of their parallel calculation patterns. However, only simple stencils with points distributed along the axes and with constan- t coefficients have been fully investigated. This study first provides insights into optimization strategies for stencils with complex shapes, including off-axial points and spatially vari- able coefficients. Through our proposed stencil-decomposition schemes, we maintain read-only coefficients in on-chip caches to avoid unvectorized memory access. To alleviate the resulting severe cache-starvation situation, a generalized cache-friendly design for many-core architecture is proposed. It can reduce cache miss times and cache space consumption. The proposed methodology significantly improves the performance of stencil operations in a real seismic imaging application and introduces a new option to write highly efficient memory-bound stencil- like loops.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/ipdpslogo.png" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>Optimizing Complex Spatially-Variant Coe cient Stencils for Seismic Modeling on GPU.</strong><br />
      Jiarui Fang, Haohuan Fu, He Zhang, et al. IEEE 21st International Conference on Parallel and Distributed Systems(ICPADS),
      <a href="assets/pdf/ICPADSfinial128.pdf">[PDF]</a>
    </p>
    <p class="abstract-text">
    The Explicit Time Evolution (ETE) method is an in- novative Finite-Difference (FD) type method to simulate the wave propagation in acoustic media with higher spatial and temporal accuracy. However, different from FD, it is difficult to achieve an efficient GPU design because of the poor memory access patterns caused by the off-axis points and spatially-variant coefficients. In this paper, we present a set of new optimization strategies for ETE stencils according to the memory hierarchy of NVIDIA GPU. To handle the problem caused by the complexity of the stencil shapes, we design a one-to-multi updating scheme for shared memory usage. To alleviate the performance damage resulted from the poor memory access pattern of reading spatially-variant coefficients, we propose a stencil decomposition method to reduce un-coalesced global memory access. Based on the state-of-the-art GPU architecture, combining with existing spatial and temporal stencil blocking schemes, we manage to achieve 9.6x and 9.9x speedups compared with a well-tuned 12-core CPUs version for 37-point and 73-point ETE stencils, respectively. Compared with a well-tuned MIC version, the best speedups for the 2 type stencils are 3.7x and 4.7x. Our designs leads to an ETE method that is 31.2x faster than conventional CPU-FD method and make it a practical seismic imaging technology.
    </p> 
  </div>
</div>

<div class="media">
  <a class="pull-left" href="#">
    <img class="media-object" src="assets/img/seglogo.jpg" width="96px" height="96px"/>
  </a>
  <div class="media-body">
    <p class="media-heading">
      <strong>GPU-based explicit time evolution method.</strong><br />
      Jiarui Fang, Haohuan Fu, Guangwen Yang, et al The 84th Society of Exploration Geophysicists Technical Program Expanded Abstracts, 2015.10
      <a href="assets/pdf/ETE_GPU_finial.pdf">[PDF]</a>
    </p>
    <p class="abstract-text">
    Finite-difference (FD) methods have long been among the most popular solutions for RTM and FWI. Compared with FD methods, the Explicit Time Evolution (ETE) method is able to simulate the wave propagation in acoustic media with higher spatial and temporal accuracy, at the cost of a more complicated memory access pattern. Similar to FD, ETE performs a stencil operation on every grid point, except that the coefficients of the stencil change spatially with the velocity parameter of that position. While FD methods already have highly-efficient designs on GPU platforms, in ETE, the sharp velocity discontinuities can result in un-coalesced memory access patterns. Moreover, the increased number of involved off-axis points in the stencil and the increased number of different coefficients bring more pressure for the fast buffers and memory in the GPU. To solve these issues, in this paper, we decompose the complex stencil into a number of sub-components, so as to form a better memory access pattern for coefficients and to simplify the calculation of stencil operations. Finally, we combine the decomposition scheme with 2.5D spatial and 1D temporal blocking optimizations. With one K20 GPU card, we manage to achieve 5.5x speedup compared against 12 cores Intel E5- E5645 CPU.
    </p> 
  </div>
</div>
